\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\author{Frode T. BÃ¸rseth}
\date{\today}
\title{Numerical exercise\\FY2045 Quantum Mechanics}
\begin{document}
\maketitle

\section{Introduction}
The one-dimensional Schr\"odinger equation in position space of a particle with mass $m$ subject to a potential $V$ reads
\begin{equation}
	\mathrm{i} \hbar \frac{\partial}{\partial t}
	\Psi ( x, t)
	=
	- \frac{\hbar^2}{2m} \frac{\partial^2}{\partial x^2}
	\Psi (x, t)
	+
	V(x)
	\Psi (x, t) \label{eq:Sch}
\end{equation}
and is the object of interest in this exercise.

The wave function is generally complex, crucially so when considering its time evolution, and we may consider the real and imaginary components to be distinct functions,
\begin{equation}
	\Psi = \Psi_R + \mathrm{i} \Psi_I,
\end{equation}
all of which in general are functions of position $x$ and time $t$. The function $\Psi_I$ in particular is real valued. Inserting this into equation \ref{eq:Sch} gives
\begin{align*}
	\mathrm{i} \hbar \frac{\partial}{\partial t}
	\Big(
	\Psi_R + \mathrm{i}\Psi_I
	\Big)
	&=
	- \frac{\hbar^2}{2m} \frac{\partial^2}{\partial x^2}
	\Big(
	\Psi_R + \mathrm{i}\Psi_I
	\Big)
	+
	V
	\Big(
	\Psi_R + \mathrm{i}\Psi_I
	\Big)\\
	\Rightarrow \;
	- \hbar \frac{\partial}{\partial t}
	\Psi_I
	+
	\mathrm{i} \hbar \frac{\partial}{\partial t}
	\Psi_R
	&=
	- \frac{\hbar^2}{2m} \frac{\partial^2}{\partial x^2}
	\Psi_R
	+
	V\Psi_R 
	+
	\mathrm{i}
	\Big(
	-
	\frac{\hbar^2}{2m} \frac{\partial^2}{\partial x^2}
	\Psi_I
	+ 
	\mathrm{i}
	V\Psi_I
	\Big)
\end{align*}

This can then be separated into two equations, one for the real component and one for the imaginary:
\begin{align}
	- \hbar \frac{\partial}{\partial t} \Psi_I
	&=
	- \frac{\hbar^2}{2m} \frac{\partial^2}{\partial x^2}
	\Psi_R
	+
	V
	\Psi_R\\
	\hbar \frac{\partial}{\partial t} \Psi_R
	&=
	- \frac{\hbar^2}{2m} \frac{\partial^2}{\partial x^2}
	\Psi_I
	+
	V
	\Psi_I
\end{align}
This is a set of partial differential equations, containing the \emph{real} functions $\Psi_R$ and $\Psi_I$.

Our strategy will be do discretize the problem. First of all, restrict the particle to the region $0 \leq x \leq L$. Then, evaluate the wave function at $N_x+1$ points on this interval, and use these points and values of $\Psi$ to approximate the continuous solution.

The discretization leads to a one-dimensional mesh of $x$ values, a distance $\Delta x$ apart, which can be expressed as $x_n = n\Delta x$. The same applies for time, which changes step by step in increments of $\Delta t$. The different discrete times at which we evaluate $\Psi$ are $t_m = m\Delta t$.

Let us now for simplicity write the different functions at each discrete point and time in the following way:
\begin{align}
	\Psi_R^{n,m} &= \Psi_R(x_n,t_m) = \Psi_R(n\Delta x,m\Delta t)\\
	\Psi_I^{n,m} &= \Psi_I(x_n,t_m) = \Psi_I(n\Delta x,m\Delta t)\\
	V^n &= V(x_n) = V(n\Delta x) \quad \quad \text{(assuming non-varying potential)}
\end{align}
With this, and permitting half-steps in time by \( \frac{1}{2} \Delta t \), we can write down the discretized partial derivatives as
\begin{align}
	\frac{\partial \Psi_F}{\partial t} (x_n,t_m)
	&\approx
	\frac{1}{\Delta t} \Big( \Psi_F^{n,m+1/2} - \Psi_F^{n,m-1/2}\Big)\\
	\frac{\partial^2 \Psi_F}{\partial x^2} (x_n,t_m)
	&\approx
	\frac{1}{\Delta x^2} \Big( \Psi_F^{n+1,m} - 2\Psi_F^{n,m} + \Psi_F^{ n-1,m} \Big)\\
\end{align}
leading to a discrete version of the above system of equations,
\begin{align}
	- 
	\frac{\hbar}{\Delta t} \Big( \Psi_I^{n,m+1/2} - \Psi_I^{n,m-1/2}\Big)
	&=
	- \frac{\hbar^2}{2m}
	\frac{1}{\Delta x^2}
	\Big(
		\Psi_R^{n+1,m} - 2\Psi_R^{n,m} + \Psi_R^{ n-1,m}
	\Big)
	+
	V^n
	\Psi_R^{n,m}\\
	\frac{\hbar}{\Delta t} \Big( \Psi_R^{n,m+1} - \Psi_R^{n,m}\Big)
	&=
	- \frac{\hbar^2}{2m}
	\frac{1}{\Delta x^2}
	\Big(
		\Psi_I^{n+1,m+1/2} - 2\Psi_I^{n,m+1/2} + \Psi_I^{ n-1,m+1/2}
	\Big)
	+
	V^n
	\Psi_I^{n,m+1/2}
\end{align}
Notice how the two functions \( \Psi_R \) and \( \Psi_I \) are out of phase, in a sense, with respect to the time index. One is half a unit ahead/behind the other. With this, finally, we can write down a way to see how this system changes from  $t_m$ to $t_{m+1}$:
\begin{align}
	\Psi_I^{n,m+1/2}
	&=
	\Psi_I^{n,m-1/2}
	+
	\frac{\hbar}{2m}
	\frac{\Delta t}{\Delta x^2}
	\Big(
		\Psi_R^{n+1,m} - 2\Psi_R^{n,m} + \Psi_R^{ n-1,m}
	\Big)
	+
	\frac{\Delta t}{\hbar}
	V^n
	\Psi_R^{n,m}\\
	\Psi_R^{n,m+1}
	&=
	\Psi_R^{n,m}
	- \frac{\hbar}{2m}
	\frac{\Delta t}{\Delta x^2}
	\Big(
		\Psi_I^{n+1,m+1/2} - 2\Psi_I^{n,m+1/2} + \Psi_I^{ n-1,m+1/2}
	\Big)
	+
	\frac{\Delta t}{\hbar}
	V^n
	\Psi_I^{n,m+1/2}
\end{align}

Now I want to rephraze this iteration scheme in the language of matrix vectors and products. Let us define a sequence of vectors $\psi_R^{m}$,
\begin{equation}
	\psi_R^{m} = ( \Psi_R^{0,m}, \ldots , \Psi_R^{N_x + 1,m} ) ^T
\end{equation}
that is, the vectors $\psi_R^0, \psi_R^1, \ldots , \psi_R^m, \ldots$ containing in index $n$ the value of $\Psi_R^{n,m}$. Then, for the tridiagonal matrix $K$,
\begin{equation}
	K
	=
	\left(
	\begin{matrix}
		-2 &  1 &   &\\
		 1 & -2 & \ddots &\\
		   &  \ddots & \ddots &1\\
		   &    & 1 & -2
	\end{matrix}
	\right)
\end{equation}
we may write the parenthesis above as the $n$th element of the matrix product $K\psi_R^m$.
\begin{equation}
	\Big(K \psi_R^m\Big)_n
	=
	\Psi_R^{n+1,m} - 2\Psi_R^{n,m} + \Psi_R^{ n-1,m}
\end{equation}
Similarly, defining the matrix $U$,
\begin{equation}
	U
	=
	\left(
	\begin{matrix}
		V^0 &  &   &\\
		 & V^1 &  &\\
		   &  & \ddots &\\
		   &    & & V^{N_x + 1}
	\end{matrix}
	\right)
\end{equation}
we may write $V^n\Psi_R^{n,m}$ as a matrix product as well, as the $n$th element of the vector given by $U \psi_R^m$
\begin{equation}
	\Big(U \psi_R^m\Big)_n
	=
	V^n\Psi_R^{n,m}
\end{equation}
Inserting this, I will rewrite the above relations between one time and the next as matrix relations.
\begin{align}
	\psi_I^{m+1/2}
	&=
	\psi_I^{m-1/2}
	+
	\frac{\hbar}{2m}\frac{\Delta t}{\Delta x ^2}
	K \psi_R^m
	-
	\frac{\Delta t}{\hbar}
	U \psi_R^m\\
	\psi_R^{m+1}
	&=
	\psi_R^m
	-
	\frac{\hbar}{2m}\frac{\Delta t}{\Delta x ^2}
	K \psi_I^{m-1/2}
	+
	\frac{\Delta t}{\hbar}
	U \psi_I^{m-1/2}
\end{align}
or, defining new scaled matrices
\begin{align}
	D &= \frac{\hbar}{2m}\frac{\Delta t}{\Delta x ^2} K\\
	P &= \frac{\Delta t}{\hbar} U
\end{align}
we can write this in a shorter way,
\begin{align}
	\psi_I^{m+1/2}
	&=
	\psi_I^{m-1/2}
	+
	D \psi_R^m
	-
	P \psi_R^m\\
	\psi_R^{m+1}
	&=
	\psi_R^{m}
	-
	D \psi_I^{m+1/2}
	+
	P \psi_I^{m+1/2}
\end{align}
These matrix equations summarize the way I wrote the program for this project. Before starting the propagation, a matrix is made for multiplication with the vectors at each step in the iteration. As we see from the equations above, the iteration is done in two steps, first find a new vector \( \psi_I \) using the old one and the newest \( \psi_R \) vector, then use it and the newest \( \psi_R \) for updating that one as well, and repeat.

The starting point then has to be two functions \( \psi_I \) and \( \psi_R \) calculated at a difference in time of \( \Delta t /2 \), which is fortunately quite easily done using the expression for the wave function that was given in the problem text.

(Looking back at my code, I now realize that I did things the other way around, starting with \( \psi_I \) in the lead, so that each iteration step started with updating \( \psi_R \). This is obviously of no real consequence when it comes to my result, yet I felt like making this clear in case of any confusion.)


\clearpage
\section{About the program}

I managed to keep my code fairly general, so that in the end each project-problem was solved by its own function, named \verb-problem_1()-, \verb-problem_2()-, etc.. They all call back to general purpose functions for most of the work. When running the program in a terminal, the problem numbers are accepted as arguments, so that one may run\\

\mbox{}
\verb-    $ python code.py 1 4 3-\\

\mbox{}
and the program will do the computations and make the graphs for problems 1, 4, and 3, in that order. Invalid (or no) arguments result in an error, and the program instead does problem 3 because that was the one I liked best.

The running time for the different problems were on my machine about as given in the following table:

\mbox{}

{\centering
\begin{tabular}{cr}
	\hline
	Problem & Time \( t \)\\
	\hline
	1 & 6 s\\
	2 & 30 s\\
	3 & 6 s\\
	4 & 300 s\\
	5 & 310 s\\
	\hline
\end{tabular}
\par}


\clearpage

\section{Problem 1}
For a wave function given by
\begin{equation}
	\Psi (x,t) = C e^{-(x-x_s)^2 / 2 \sigma_x^2 } e^{ \mathrm{i} (k_0 x - \omega t ) }
	\label{eq:initial}
\end{equation}
we can determine the constant \( C \) by the normalization requirement
\begin{equation}
	\int\limits_{- \infty}^{ \infty} \mathrm{d}x \; | \Psi (x,t) |^2 = 1.
\end{equation}
Inserting the expression in \ref{eq:initial} here, we see that \( C \) must satisfy
\begin{equation}
	C = \left( \int\limits_{- \infty}^{ \infty} \mathrm{d}x \;  e^{-(x-x_s)^2 / \sigma_x^2 } \right)^{-1/2}
\end{equation}
where the complex exponentials canceled after conjugation and squaring, as was the number 2 in the fraction of the gaussian. The integral in the parenthesis above evaluates to \( \sqrt{ \pi \sigma_x^2 } \), and so we conclude that
\begin{equation}
	C = \left( \pi \sigma_x^2 \right)^{-1/4}
\end{equation}
This should in theory normalize \( \Psi \), but I will make sure to do it numerically as well, just to be sure.

I placed this wave function in a box with zero potential inside, deciding on values \( x_s = 5 \) and \( \sigma_x = 1.0 \). As for \( \Delta x \), I decided that each period of the wave would need at least 15 measurement points. In other words,
\begin{equation}
	15\Delta x k_0 \approx 2 \pi \quad \Rightarrow \quad \Delta x \approx \frac{ 2\pi }{ 15 k_0 } \approx \frac{2}{5 \: k_0}
\end{equation}
and since \( \Delta x = L / (N_x -1 ) \), I decided on values for \( N_x, \Delta x \) by
\begin{equation}
	N_x = \left\lceil \frac{ 5 }{ 2 } k_0 L \right\rceil \quad \quad \Delta x = \frac{ L }{ N_x -1 }	
\end{equation}

However, I let the imaginary part \( \Psi_I \) make a small step ahead of the real part \( \Psi_R \), as instructed by the problem text. Iterating in two-part steps, using the machinery detailed in the previous section, I then let the wave function propagate until it reached \( x=15 \), and renormalized it at regular intervals (which actually did not appear to be necessary, but I kept it in all the same).

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{./img/prob1a1.png}
~
\includegraphics[width=0.4\textwidth]{./img/prob1b1.png}\\
\includegraphics[width=0.4\textwidth]{./img/prob1a2.png}
~
\includegraphics[width=0.4\textwidth]{./img/prob1b2.png}
\caption{Graphs showing a wave function having propagated from one side of the box to another, with the square of the wave function shown at both times as well.}
\label{fig:prob1}
\end{figure}

In figure \ref{fig:prob1} are graphs showing the wave function at times 0 and \( T \). The end time \( T \) is given by the group velocity \( v_g \), which in turn depends on  \( \omega \) by
\begin{equation}
	v_g = \left. \frac{ \partial \omega }{ \partial k } \right|_{k=k_0} = \frac{ \hbar k_0 }{ m }	
\end{equation}
and since we want the wave to move a distance \( L/2 \), the time \( T \) becomes
\begin{equation}
	T = \frac{ L }{ 2v_g }
\end{equation}
Thus, the wave top moves from 5 to 15, a distance of 10.


\clearpage
\section{Problem 2}

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{./img/prob2-01a.png}
~
\includegraphics[width=0.4\textwidth]{./img/prob2-01b.png}\\
\includegraphics[width=0.4\textwidth]{./img/prob2-02a.png}
~
\includegraphics[width=0.4\textwidth]{./img/prob2-02b.png}\\
\includegraphics[width=0.4\textwidth]{./img/prob2-03a.png}
~
\includegraphics[width=0.4\textwidth]{./img/prob2-03b.png}\\
\includegraphics[width=0.4\textwidth]{./img/prob2-04a.png}
~
\includegraphics[width=0.4\textwidth]{./img/prob2-04b.png}\\
\includegraphics[width=0.4\textwidth]{./img/prob2-20a.png}
~
\includegraphics[width=0.4\textwidth]{./img/prob2-20b.png}\\
\caption{The result of propagating wave functions with distinct values for \( \sigma_x \) by a time \( T = L/2v_g \). From top to bottom, the graphs show the outcome for \( \sigma_x = 0.1,\: 0.2, \: 0.5,\: 1.0,\: 2.0 \). Evidently, if the position is too certain at time \( t=0 \), i.e. \( \sigma_x \) is too small, the wave function spreads out with time.}
\label{fig:prob2}
\end{figure}
Repeating this for different values of \( \sigma_x \), I obtained the graphs in figure \ref{fig:prob2}. As we see, a small \( \sigma_x \) results in a wide distribution at later times. One interpretation of this might be that the position at time \( t=0 \) is too certain, resulting in high degree of uncertainty in the momentum, which in turn leads to the distribution spreading out. For larger values of \( \sigma_x \), on the other hand, we see that the gaussian shaped wave is more stable while propagating.

To test out different values for \( \Delta t \), I made a variable \( \rho \) to scale the time step relative to the expression found in the stability section of the problem text. That is, I set
\begin{equation}
	\Delta t = \rho \frac{ \hbar }{ V_{max} + \hbar/2m \Delta x^2 }
	 = \rho \frac{ 2m \Delta x^2 \hbar }{ 2m \Delta x^2 V_{max} + \hbar }
\end{equation}
I adjusted the variable \( \rho \) somewhat randomly, and there was a very clear difference between what I would consider a correct outcome and an incorrect one. For too high values of \( \rho \), the graph would still produce wave-shaped graphs, but with divergent amplitudes, or strange behaviour near the endpoints. The periods seemed to be very high, as the entire area under the function were coloured by lines zig-zagging up and down. An example is included in figure \ref{fig:prob2weird}.
\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{./img/prob2-weirda.png}
~
\includegraphics[width=0.4\textwidth]{./img/prob2-weirdb.png}\\
\caption{The result of attempting to propagate a wave with \( \rho = 0.501 \), and initial wave having \( \sigma_x = 0.5 \). Notice the very large amplitude of the resulting wave, even for this very small deviation from \( \rho = 0.5 \).}
\label{fig:prob2weird}
\end{figure}

After some searching I noticed that there seemed to be a fairly clear border at a value of \( \rho = 0.5 \). Even a tiny bit larger, and the amplitudes would diverge, but for values lower, or even precisely at \( \rho = 0.5 \), the  problem disappeared.

For the rest of my computations I set the value of this constant to \( \rho = 0.1 \), slightly smaller than the apparent limit 0.5.


\clearpage
\section{Problem 3}

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{./img/prob3.png}
\caption{The result of sending a wave packet with \( \sigma_x = 1.0 \) into a potential wall of height \( V_{max} = \frac{1}{2} E, \) and width \( b = L/50 \). The potential is included in red, but not to scale.}
\label{fig:prob3}
\end{figure}

The result of sending a wave packet of width \( \sigma_x \) into a potential wall as described in the problem text is shown in figure \ref{fig:prob3}. The height of the potential wall was \( V_{max} = \frac{1}{2} E \), and its width \( b=L/50 \). Evidently, for these parameters the particle will transmit through the barrier more ofen than it is reflected. To be more precise, the transmition and reflection probabilities were found to be
\begin{equation}
  p_r = 0.0624, \quad
	p_t = 0.9376
\end{equation}



\clearpage
\section{Problem 4}

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{./img/prob4.png}
\caption{A graph showing how changing the size of \( V_{max} \) relative to \( E \) will affect the transmission and reflection probabilities.}
\label{fig:prob4}
\end{figure}

Figure \ref{fig:prob4} shows how the reflection and transmission probabilities are affected by the size of the potential barrier. Producing this graph took my program around 5 minutes.

As in the classical case for scattering, the transmission probability goes to zero for potentials barriers equal or higher than the energy \( E \) of the particle. However, typical for quantum mechanical systems, this classically hard border has been smoothed out. There is still reflection happening for barriers smaller than this, and some probability of transmission for potential barriers larger than \( E \).

The dip around 0.6 I am not sure how to explain, but I am fairly sure that it is representative of the behaviour of the system. Perhaps at this relation between barrier and particle energy there is some constructive resonance leading to a slight peak in reflection, but this is guesswork and I am not certain on what to blame this phenomenon.



\clearpage
\section{Problem 5}

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{./img/prob5.png}
\caption{A graph showing how changing the width of the potential barrier affects the transmission and reflection probabilities.}
\label{fig:prob5}
\end{figure}

Figure \ref{fig:prob5} shows how the reflection and transmission probabilities are affected by the width of the potential barrier. As with the graph in problem 4, producing this plot required 50 computations, which again took about 5 minutes on my computer.

A strange thing appears to be happening as the width increases: The probabilities even out and both approach 0.5. As the wave function propagates in a wide barrier, it looks like it loses track of which side it entered, and both ends become equally valid exits. For thinner potentials there is some tradeoff, and it is worth noting that there are multiple peaks and valleys, indicating that interference in the barrier, constructive and destructive, play a role.

\end{document}
